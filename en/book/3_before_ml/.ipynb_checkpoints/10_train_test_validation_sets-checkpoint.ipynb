{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae79413",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3e9da",
   "metadata": {},
   "source": [
    "It's time to talk about what is perhaps the most popular method in scikit-learn, the one that helps us divide a dataset into different sets of information.\n",
    "\n",
    "By now, you should clearly understand the importance of performing this division, so we won't dwell too much on the why, but rather on the how.\n",
    "\n",
    "We start by importing the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ae6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a55131",
   "metadata": {},
   "source": [
    "In reality, the method is quite simple to use, but there are some tricks you should keep in mind to get the most out of it.\n",
    "\n",
    "## Interface\n",
    "\n",
    "This function has a somewhat peculiar interface, as it is designed to receive a variable number of arguments. To illustrate, look at the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate some example data\n",
    "X1 = np.arange(0, 100)\n",
    "X2 = np.arange(100, 200)\n",
    "X3 = np.arange(200, 300)\n",
    "\n",
    "print(f\"Shapes: {X1.shape}, {X2.shape}, {X3.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X1_train, X1_test, X2_train, X2_test, X3_train, X3_test = train_test_split(X1, X2, X3)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shapes after splitting:\")\n",
    "print(f\"X1_train: {X1_train.shape}, X1_test: {X1_test.shape}\")\n",
    "print(f\"X2_train: {X2_train.shape}, X2_test: {X2_test.shape}\")\n",
    "print(f\"X3_train: {X3_train.shape}, X3_test: {X3_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33e197",
   "metadata": {},
   "source": [
    "But don't worry if that seems a bit complex. The most common use case is simpler, where you pass a dataset and its corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1163345",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 2)\n",
    "y = np.random.randint(0, 2, 100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285c551",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "\n",
    "### Set Sizes\n",
    "\n",
    "By default, and without additional arguments, the dataset sizes will be divided into 75% for the training set and 25% for the test set.\n",
    "\n",
    "These values are modifiable, of course. You can use the `test_size` or `train_size` parameters to modify the size (remember to set only one), and you can use both integer and float values.\n",
    "\n",
    "If you use an integer value, that exact number will be used, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4098a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10)\n",
    "\n",
    "print(\"Shapes after splitting:\")\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771917c",
   "metadata": {},
   "source": [
    "But you can also use floats, which will serve as percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "\n",
    "print(\"Shapes after splitting:\")\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdbb52",
   "metadata": {},
   "source": [
    "### Random seed\n",
    "\n",
    "By default, the function randomly assigns the data to either of the two sets, so two executions will not give us the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ea62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.arange(0, 100)\n",
    "\n",
    "X_train, X_test = train_test_split(X1, train_size=0.5)\n",
    "print(\"First 10 elements of X_train:\", X_train[:10])\n",
    "\n",
    "X_train, X_test = train_test_split(X1, train_size=0.5)\n",
    "print(\"First 10 elements of X_train:\", X_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4bd64",
   "metadata": {},
   "source": [
    "If what you want is reproducibility, you can set a random seed using the `random_state` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f0a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.arange(0, 100)\n",
    "\n",
    "X_train, X_test = train_test_split(X1, train_size=0.5, random_state=42)\n",
    "print(\"First 10 elements of X_train:\", X_train[:10])\n",
    "\n",
    "X_train, X_test = train_test_split(X1, train_size=0.5, random_state=42)\n",
    "print(\"First 10 elements of X_train:\", X_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b983d54-da48-48aa-af7f-8599084eedf9",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Typically, `random_state` is fixed during development and experimentation for several important reasons:\n",
    "\n",
    "1. **Reproducibility**: By setting a fixed `random_state`, you ensure that your data splits remain consistent across multiple runs. This is crucial for debugging, iterating on your model, and comparing different approaches.\n",
    "\n",
    "2. **Consistency in Results**: When you're tweaking hyperparameters or trying different model architectures, a fixed `random_state` helps isolate the impact of your changes. You can be confident that any differences in results are due to your modifications, not random variation in the data split.\n",
    "\n",
    "3. **Easier Collaboration**: When working in a team, using a fixed `random_state` allows all team members to work with the same data splits, making it easier to compare results and reproduce each other's work.\n",
    "\n",
    "4. **Debugging**: If you encounter issues or unexpected results, a fixed `random_state` makes it easier to recreate the problem and investigate its cause.\n",
    "\n",
    "However, it's important to note that while fixing `random_state` is beneficial during development, it shouldn't be the end of your evaluation process. \n",
    "\n",
    "Once you've settled on a model, it's a good practice to test it with different random splits (by changing the `random_state` or not setting it) to ensure your model's performance is robust across different data divisions. And in a production environment, you might want to regularly retrain your model on fresh data, in which case you wouldn't use a fixed `random_state`.\n",
    "\n",
    "Remember, the goal is to develop a model that generalizes well to unseen data, not one that performs well on a single, fixed split. Use a fixed `random_state` as a development tool, but don't rely on it exclusively for your final model evaluation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407937e",
   "metadata": {},
   "source": [
    "**Stratification**\n",
    "\n",
    "When working with imbalanced datasets (those that have more data from one class than others), you can set the `stratify` argument to ensure that the data is distributed evenly between the two sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed73b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_counts(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    counts = dict(zip(unique, counts))\n",
    "    for class_, count in counts.items():\n",
    "        print(f\"Class {class_}:\\t{count:>5} ({count/len(y)*100:00.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4db2c",
   "metadata": {},
   "source": [
    "We create a sample dataset, pay attention to the counts of the \"apple\" and \"orange\" labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecfc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100000\n",
    "X = np.random.rand(sample_size, 2)\n",
    "y = np.random.choice([\"apple\", \"orange\", \"banana\"], sample_size, p=[0.90, 0.05, 0.05])\n",
    "\n",
    "show_counts(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023f322",
   "metadata": {},
   "source": [
    "If we divide them without stratification, pay attention to what happens with the counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=45)\n",
    "\n",
    "print(\"Training split:\")\n",
    "show_counts(y_train)\n",
    "print()\n",
    "print(\"Test split:\")\n",
    "show_counts(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdff60b",
   "metadata": {},
   "source": [
    "But if we do it by stratifying with `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=60, stratify=y)\n",
    "\n",
    "show_counts(y_train)\n",
    "# print(\n",
    "show_counts(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6b84d",
   "metadata": {},
   "source": [
    "### Do not randomize\n",
    "\n",
    "By default, the function separates the data randomly, but there will be occasions when this is not ideal, for example, when working with time series data. In these cases, taking data randomly would cause a *data leakage* problem. Scikit-learn allows us to disable randomization by passing the `shuffle` argument equal to false:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(20)\n",
    "\n",
    "print(\"Original elements of X:\", X)\n",
    "\n",
    "X_train, X_test = train_test_split(X, shuffle=False, test_size=0.5)\n",
    "\n",
    "print(\"First 10 elements of X_train:\", X_train[:10])\n",
    "print(\"First 10 elements of X_test:\", X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9534b6",
   "metadata": {},
   "source": [
    "But if we call it without `shuffle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.5)\n",
    "\n",
    "print(\"First 10 elements of X_train:\", X_train[:10])\n",
    "print(\"First 10 elements of X_test:\", X_test[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe3318",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I hope you now have a clear understanding of the `train_test_split()` method and how to adjust the arguments to meet the needs of your dataset. Remember that this is an important step in creating accurate and effective machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1192069-4c20-4d06-95d2-8ebf43ab8ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
