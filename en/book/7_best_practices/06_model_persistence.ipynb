{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae39974",
   "metadata": {},
   "source": [
    "# Persistencia de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3dab56",
   "metadata": {},
   "source": [
    "Hello, welcome back to your machine learning book with scikit-learn.\n",
    "\n",
    "You have everything ready, you're happy with your model and all the vectorizers and transformers you trained to make it work. But what's next? It's time to save it to disk for distribution and deployment.\n",
    "\n",
    "To continue in this chapter, I'm going to load, create, and train a scikit-learn pipeline which, for practical purposes, is a scikit-learn model. If you want to know more details, check out the chapter on pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def load_trained_model():\n",
    "# Generate synthetic data\n",
    "\tnp.random.seed(0)\n",
    "\tX = np.random.rand(100, 1)\n",
    "\ty = 2 * X + 1 + 0.1 * np.random.randn(100, 1)\n",
    "\t\n",
    "\t# Split the data into training and testing sets\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\t\n",
    "\t# Create a linear regression model\n",
    "\tmodel = LinearRegression()\n",
    "\t\n",
    "\t# Train the model using the training data\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\n",
    "\treturn model\n",
    "\n",
    "model = load_trained_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f02315",
   "metadata": {},
   "source": [
    "Remember that this is already a trained model.\n",
    "\n",
    "## Pickle\n",
    "\n",
    "Traditionally, models were serialized to disk using `pickle`, the default library for serializing objects in Python.\n",
    "\n",
    "Saving a model is simple with pickle, what you need to do is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model.pickle\", \"wb\") as wb:\n",
    "\tpickle.dump(model, wb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162ad14",
   "metadata": {},
   "source": [
    "This will serialize the model into the \"model.pickle\" file, which is already a file that we can share with someone else or put into production ourselves. To read it from disk, it is necessary to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pickle\", \"rb\") as rb:\n",
    "\tunpickled_model = pickle.load(rb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815084cd",
   "metadata": {},
   "source": [
    "We can verify that it is the type we are expecting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(unpickled_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53861766",
   "metadata": {},
   "source": [
    "And make predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2c9f5",
   "metadata": {},
   "source": [
    "### Disadvantages\n",
    "\n",
    "However, pickle has serious security flaws and is not the recommended way to persist your models as it allows arbitrary code execution during deserialization. I recommend using pickle if, and only if, you have no other alternative.\n",
    "\n",
    "## Joblib\n",
    "\n",
    "There is another library called `joblib` that is optimized for serializing large NumPy arrays. But internally, it ends up using pickle for many of its tasks, so they share the same problems.\n",
    "\n",
    "I will show you how to use it for completeness in this book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(model, \"model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa397ff1",
   "metadata": {},
   "source": [
    "And to load it, it's done like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ca9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "model_joblibbed = load(\"model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd5ab3",
   "metadata": {},
   "source": [
    "Review the type and make some predictions so you can see that it does work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_joblibbed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d936efa",
   "metadata": {},
   "source": [
    "Although Joblib is an improvement over Pickle, this improvement is in aspects of speed and size of the stored model, but nothing changes in terms of security. That's why I recommend that you don't use Joblib unless you have no other alternative.\n",
    "\n",
    "## Skops\n",
    "\n",
    "Recently, a new library called skops emerged, whose objective is to help save machine learning models and put them into production.\n",
    "\n",
    "This library is not part of scikit-learn, but is\n",
    "\n",
    "It is simple to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce397a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skops.io as sio\n",
    "\n",
    "sio.dump(model, \"model.sio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b38d3",
   "metadata": {},
   "source": [
    "And to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8501f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skopted_model = sio.load(\"model.sio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b25d62c",
   "metadata": {},
   "source": [
    "Check the type and make some predictions so you can see that it does work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92294787",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(skopted_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9d039",
   "metadata": {},
   "source": [
    "## About extensions\n",
    "\n",
    "In reality, the extensions you assign to your model don't matter at all, since in the end, to read or write them to disk, you'll need to specify the complete path to the file.\n",
    "\n",
    "## Other recommendations\n",
    "\n",
    "Saving models is just one part of putting our models into production. Other things you should do are:\n",
    "\n",
    "1. **Maintain consistent library versions**: Make sure to use the same versions, or compatible ones, of scikit-learn and its dependencies when saving and loading models. This ensures compatibility and consistent model behavior.\n",
    "2. **Include preprocessing steps**: Save trained preprocessing transformers along with the model. You can achieve this by creating a pipeline that includes all steps and saving the entire pipeline.\n",
    "3. **Document your model**: Consider documenting the model's purpose, performance metrics, dataset used for training, feature engineering, and any other relevant information. This documentation will help you and others understand the context, limitations, and use cases of the model.\n",
    "4. **Use a version control system**: Store your saved models and associated files (e.g., data preprocessing scripts, configuration files, and documentation) in a version control system like Git.\n",
    "5. **Back up your models**: Ensure that your saved models are backed up in a secure and reliable storage system. This could involve saving models in cloud storage or using a dedicated backup solution.\n",
    "6. **Ensure the model works after saving and opening**: After saving a model, test loading it and making predictions to ensure that the serialization and deserialization process works as expected.\n",
    "\n",
    "And that's all, I hope these tips help you to successfully put your model into production."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
