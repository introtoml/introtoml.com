{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e17b6917",
   "metadata": {},
   "source": [
    "# Feature hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a47ca8",
   "metadata": {},
   "source": [
    "Hello, welcome back to this Machine Learning book with scikit-learn. In this chapter, I will talk about how one can deal with high-cardinality categorical data, that is, those variables that can take on many values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edaa621",
   "metadata": {},
   "source": [
    "In machine learning, there is a well-known technique called *feature hashing* or, among friends, the *hashing trick*. This technique involves applying a hash function to the value of a feature to associate it with a position within an array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e212f9",
   "metadata": {},
   "source": [
    "The basic idea behind hashing is to convert an input into a more compact and easier-to-process form. Instead of storing a complete list of all features in their original form, the input is transformed into a simpler numerical representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2c032",
   "metadata": {},
   "source": [
    "Let's see it with an example, we'll start by creating an array of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'apple': 2, 'banana': 1, 'orange': 3},\n",
    "        {'banana': 4, 'orange': 1},\n",
    "        {'kiwi': 3, 'pineapple': 5}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ccfbc",
   "metadata": {},
   "source": [
    "Then we import the `FeatureHasher` class from the `sklearn.feature_extraction` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f49523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389677e8",
   "metadata": {},
   "source": [
    "And we create an object of the class, setting the `n_features` parameter, which in turn will represent the number of inputs in the resulting vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba72eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = FeatureHasher(n_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1cd9c5",
   "metadata": {},
   "source": [
    "And then we can call the `fit_transform` method to transform our dataset in a single action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_data = hasher.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f36d5c",
   "metadata": {},
   "source": [
    "The result of executing transform with our data is always a sparse matrix given the typical use of the `FeatureHasher` class, which is why here I'm converting it back to a NumPy array using the `todense` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_data.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32cab8e",
   "metadata": {},
   "source": [
    "If the results are not what you expected, I understand, at first glance it's difficult to interpret what the hasher is doing. For now, just remember that we obtained 4-dimensional vectors, exactly as we specified in the constructor with `n_features` equal to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ebd99a",
   "metadata": {},
   "source": [
    "## Extra Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a9c9c",
   "metadata": {},
   "source": [
    "In the previous example, we used dictionaries as input values; however, it is also common to use strings as inputs. For this, we can set the `input_type` argument as `string`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = FeatureHasher(n_features=4, input_type='string')\n",
    "hashed_data = hasher.transform([\n",
    "    ['cat', 'dog', 'bird'],\n",
    "    ['cat', 'bird'],\n",
    "    ['fish', 'dog'],\n",
    "])\n",
    "hashed_data.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e3287",
   "metadata": {},
   "source": [
    "## Explanation of the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af19c0",
   "metadata": {},
   "source": [
    "Returning to the resulting confusing values, this happens because when there are hash functions involved in a process, we are bound to suffer collisions, particularly if we have a sufficiently low number of features, as in our case with `n_features` equal to 4. This causes different values to be assigned the same position within the vector. To mitigate the effects of this collision, `FeatureHasher` has another function responsible for determining the sign of the value to be added, with the purpose of having collisions cancel each other out, which is why you may also see negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f01699",
   "metadata": {},
   "source": [
    "```{hint} For homework, I leave it to you to experiment with the value of `n_features`, choose a sufficiently large value to prevent collisions. The scikit-learn recommendation is that this value should always be a power of two.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf6008",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16efa1a6",
   "metadata": {},
   "source": [
    "While feature hashing is a powerful technique used in ML, it is not as beneficial to apply it in all scenarios, particularly when we have attributes with low cardinality, since as we saw in the example, when `n_features` has a low value, using *hashing* can cause us to lose information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c2a62a",
   "metadata": {},
   "source": [
    "In these cases, other techniques such as one-hot encoding or label encoding may be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140aa5ab",
   "metadata": {},
   "source": [
    "Want to learn how to work with text? See you in the next chapter."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
