{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16d0955",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e4708",
   "metadata": {},
   "source": [
    "Hello, welcome to this chapter where we will explore some other scikit-learn tools that will help us create more and better models.\n",
    "\n",
    "The first thing we'll look at is called cross-validation.\n",
    "\n",
    "Cross-validation is a technique that allows us to evaluate the performance of a machine learning model.\n",
    "\n",
    "We already know that training a model with a dataset and testing it on the same dataset is a mistake, which is why we usually divide the data into two sets: training and testing.\n",
    "\n",
    "It's useful because instead of dividing the data into two static training and test sets as we're normally accustomed to, this technique divides the data into multiple sets called \"folds\".\n",
    "\n",
    "Let's say you have this data. What cross-validation does is divide it into N groups of roughly similar size.\n",
    "\n",
    "So the distribution of the data looks like this:\n",
    "\n",
    "It then iterates over all combinations of this data, using a different training set for each iteration and also evaluating on a different set each time. This will give us N measures of how good our algorithm is.\n",
    "\n",
    "This training method is useful for getting a better estimate of the model on unseen data, which becomes more relevant when we don't have a large dataset.\n",
    "\n",
    "The go-to method for applying and calculating cross-validation in scikit-learn is the `cross_val_score` function.\n",
    "\n",
    "## The `**cross_val_score**` function\n",
    "\n",
    "One of the easiest ways to use cross-validation is through the `cross_val_score` function. This is a function that trains and tests a model on each and every one of the folds generated by cross-validation.\n",
    "\n",
    "What happens inside the function is that at each iteration a new model is created and trained, then evaluated and the score it receives is stored in an array. This array will be returned as the result of the function.\n",
    "\n",
    "To see it with an example, let's load a dataset and a machine learning model. In a future chapter we'll look at models in more detail, for now, simply execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab74a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "X, y = iris_dataset.data, iris_dataset.target\n",
    "\n",
    "X[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973681a",
   "metadata": {},
   "source": [
    "Now, to use `cross_val_score`, you need to import the function from `sklearn.model_selection`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07dc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d30c30",
   "metadata": {},
   "source": [
    "And we proceed to use it by passing the untrained model, input data, and label as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963163f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed406b57",
   "metadata": {},
   "source": [
    "Depending on the size of your data, the function may take some time.\n",
    "\n",
    "Remember what is happening internally: your data is being divided into 5 segments, a value that we are setting in this case with the `cv` argument. Each of these segments will be used to test the performance of a model trained on the remaining segments.\n",
    "\n",
    "If we visualize the function's result, you will see 5 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b410bf8",
   "metadata": {},
   "source": [
    "Each of these values represents the model's score in each of these cross-validation segments. In this case, the model obtained a high score in most segments, suggesting that the model we passed to the function has acceptable performance.\n",
    "\n",
    "### How do I train a model with `cross_val_score`?\n",
    "\n",
    "While the function trains models, it only does so for the purpose of evaluating performance. If all the scores returned by the function are acceptable, you can proceed to train a final model using all your training data. This would be the model you should test with your test set and subsequently move to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe555a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be834e93",
   "metadata": {},
   "source": [
    "## Other arguments\n",
    "\n",
    "The base arguments of the function are the estimator, or the model to test, the input variables, and the label. Optionally, we can specify how many segments we want to use with the `cv` argument by passing an integer.\n",
    "\n",
    "You might be wondering, what metric is it using to measure performance? â€“ By default, `cross_val_score` uses an evaluation metric specific to the estimator in question. For example, for a logistic regression classifier, the default metric is accuracy (`accuracy`), while for a regression model, the default metric is the coefficient of determination R-squared (`R^2`). However, a different metric can be specified through the `scoring` argument if you want to use a different evaluation measure than the default one.\n",
    "\n",
    "For example, let's say you want to use 6 segments and instead of using `accuracy`, we're more interested in knowing the precision of the model. We would have to call `cross_val_score` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e987dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv = 6, scoring='precision_macro', verbose = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46fc05",
   "metadata": {},
   "source": [
    "If you notice, I'm also specifying `verbose` equal to 3, which controls the amount of information printed during cross-validation. A higher `verbose` value prints more information, while a lower value prints less information. Useful for when you want to know what's happening.\n",
    "\n",
    "## The `**cross_validate**` function\n",
    "\n",
    "There's another even more generic function than `cross_val_score` that receives the same arguments. The main difference between them is that `cross_validate` allows you to specify multiple metrics for evaluation and returns more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_validate(model, X, y, cv = 6, \n",
    "\tscoring=[\n",
    "\t\t'precision_macro', \n",
    "\t\t'precision_micro',\n",
    "\t\t'accuracy'\n",
    "\t],\n",
    "\tverbose = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d955cc",
   "metadata": {},
   "source": [
    "And the result is a dictionary with more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in scores.items():\n",
    "    print(key)\n",
    "    print(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7e01c",
   "metadata": {},
   "source": [
    "And there you have it, this book section covered cross-validation and how it can be used in scikit-learn. Remember that this is an important technique in machine learning, and it's recommended to use it whenever possible. However, it's important to consider the computational complexity and resources that would be consumed when working with a large amount of data.\n",
    "\n",
    "That's why cross-validation is especially useful when you have a small dataset and want to estimate the performance of a model reliably.\n",
    "\n",
    "Join me in the next chapter, where we'll discuss the hyperparameters of our model."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
