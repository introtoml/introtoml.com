{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afed430",
   "metadata": {},
   "source": [
    "# Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5dfbe4",
   "metadata": {},
   "source": [
    "Hello again, do you know what cross-validation is? Well, we're going to use it a bit for the topic of this chapter.\n",
    "\n",
    "You know that to train a machine learning model, it's necessary to establish some values and configurations to modify the training behavior; these are known as hyperparameters. To give an example of these hyperparameters, take the `RandomForestRegressor` class (we'll look at the machine learning algorithms that sklearn offers us later, don't worry about it for now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a781c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models = RandomForestRegressor(\n",
    "    n_estimators = 10,\n",
    "    criterion = \"gini\",\n",
    "    max_depth = 10,\n",
    "    max_leaf_nodes = 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c860ef9",
   "metadata": {},
   "source": [
    "Where the hyperparameters are: the number of trees, the splitting criterion, the maximum depth, and the minimum number of samples per leaf.\n",
    "\n",
    "These values have a significant impact on the model's performance and can be the difference between a poor model and one that works perfectly.\n",
    "\n",
    "Although the default hyperparameters in scikit-learn classes are reasonable values, they are not necessarily optimal for all datasets or all machine learning problems. Therefore, it is important to perform a hyperparameter search to find the optimal values that maximize the model's performance across all our datasets.\n",
    "\n",
    "Conducting this search takes time and effort, but it is an investment worth making for the improvement these parameters represent in our model.\n",
    "\n",
    "Scikit-learn offers us several options when it comes to searching for these hyperparameters systematically rather than manually.\n",
    "\n",
    "The techniques are: *grid search* and *random search*. Each has its advantages and disadvantages; in this book, I will discuss random search:\n",
    "\n",
    "Just a small note, in scikit-learn, hyperparameter searches are always connected with cross-validation to ensure that the chosen values are a correct choice for the dataset.\n",
    "\n",
    "## Random search\n",
    "\n",
    "Now, let's see an example in a regression problem.\n",
    "\n",
    "First, let's load the dataset and split it into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_dataset = fetch_california_housing()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\thousing_dataset.data,\n",
    "\thousing_dataset.target,\n",
    "\trandom_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee113f1",
   "metadata": {},
   "source": [
    "Then we will create a regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a396c7",
   "metadata": {},
   "source": [
    "We must define the parameter space in which we are going to search - this search space will be used by Random Search to randomly generate combinations of hyperparameters. These combinations will be used to create new instances of our RandomForestRegressor and run cross-validation on them, thus evaluating how good they are to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the parameters are\n",
    "# commented out because they will\n",
    "# take too long to execute, but you\n",
    "# can try them out!\n",
    "\n",
    "param_distributions = {\n",
    "    # 'n_estimators': [100, 1000, 2000],\n",
    "    # 'criterion': [\"squared_error\", \"absolute_error\", \"friedman_mse\"],\n",
    "    # 'max_depth': [None, 10, 100],\n",
    "    'max_features': [\"sqrt\", \"log2\"],\n",
    "    'max_leaf_nodes': [\n",
    "        None, 10, \n",
    "        # 100, 1000\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f172a3d",
   "metadata": {},
   "source": [
    "And finally, we import the `RandomizedSearchCV` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de127790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e361c9",
   "metadata": {},
   "source": [
    "We create an instance, passing it the model and the set of parameters. Then we specify the number of iterations; remember that the search is random, the number of iterations specifies how many attempts we will make to find the best hyperparameters. With `cv` we specify the number of subsets for cross-validation, and finally, we set the random state to 42 to make the result reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab001b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(model, param_distributions, n_iter=10, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98f767",
   "metadata": {},
   "source": [
    "Finally, we call `fit` to begin the search; this receives the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493175e7",
   "metadata": {},
   "source": [
    "This will take a little while, but when finished we'll be able to access the best parameters using the `best_params_` attribute and we can evaluate the best model obtained through the `score` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87908f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejores hiperparámetros: \", search.best_params_)\n",
    "print(\"Puntuación de prueba: \", search.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0420e",
   "metadata": {},
   "source": [
    "## Training a model with the best parameters\n",
    "\n",
    "To train the final model, we can take the best hyperparameters and pass them to the constructor. This creates a fresh model with the ideal configuration we just obtained and trains it with all of our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestRegressor(**search.best_params_)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551e146",
   "metadata": {},
   "source": [
    "```{hint}\n",
    "As an exercise, practice using a grid search, utilizing \\`GridSearchCV\\`. Be careful when using too many parameters because grid search takes time to execute.\n",
    "```\n",
    "\n",
    "## Does not guarantee the best solution\n",
    "\n",
    "It's important to note that hyperparameter search does not guarantee finding the optimal set of hyperparameters for a given model. The optimal combination of hyperparameters may not be within the manually specified search space. Therefore, it's important to consider hyperparameter search as an iterative process that may require several iterations to reach an optimal set of hyperparameters for a given model.\n",
    "\n",
    "## In conclusion\n",
    "\n",
    "Hyperparameter search is a crucial step when you want to get the most out of your data. In scikit-learn, this search is strongly linked to cross-validation, although in theory, they are two independent concepts.\n",
    "\n",
    "scikit-learn offers two methods for hyperparameter search: GridSearchCV and RandomizedSearchCV. The first performs an exhaustive search over all possible combinations of specified hyperparameter values, while the second performs a random search of a subset of combinations. In general, RandomizedSearchCV can be more efficient than GridSearchCV when the hyperparameter search space is large.\n",
    "\n",
    "Also remember that it's not a magical solution, and sometimes you need to iterate on choosing the best search space."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
